<!doctype html><html lang="en"><head><meta http-equiv="x-ua-compatible" content="ie=edge"><meta charset="utf-8"><meta name="viewport" content="width=device-widthinitial-scale=1"><title>Tim Cech</title><meta name="description" content="ToDo"><meta name="robots" content="index, follow"><link rel="stylesheet" href="/glightbox.min.css"><link rel="stylesheet" href="/styles.css"><link rel="shortcut icon" href="/favicon.ico"><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"><link rel="icon" type="image/png" sizes="48x48" href="/favicon-48x48.png"><noscript><style class="js-only">{ display: none; }</style></noscript></head><body id="page-top" data-spy="scroll"><section class="container" id="publications"><div class="row text-center"><div class="col-12"><h2>All <strong>Publications</strong></h2><p><a class="text-secondary" href="/index.html#publications">by <strong>Tim Cech</strong></a></p><p class="pt-0">Research Profiles:&ensp;<a href="https://orcid.org/0000-0001-8688-2419">ORCID</a><br class="d-inline d-sm-none"><span class="d-none d-sm-inline">&ensp;|&ensp;</span><a href="https://www.researchgate.net/profile/Tim-Cech-2">Research Gate</a><br class="d-inline d-sm-none"><span class="d-none d-sm-inline">&ensp;|&ensp;</span><a href="https://scholar.google.de/citations?user=phn3_p8AAAAJ">Google Scholar</a></p></div></div><div class="row" id="2023-kdir-unblock"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2023-kdir-uncover.webp" alt="Thumbnail of unCover: Identifying AI Generated News Articles by Linguistic Analysis and Visualization"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>unCover: Identifying AI Generated News Articles by Linguistic Analysis and Visualization</h3><p></p>15th International Conference on Knowledge Discovery and Information Retrieval (KDIR 2023),<p><small>Lucas Liebe, Jannis Baum, Tilman Schütze, Tim Cech, Willy Scheibel, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2023-kdir-unblock">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2023-kdir-unblock">BibTeX</a></p><div class="collapse abstract" data-bs-target id="abstract-2023-kdir-unblock"><p>Text synthesis tools are becoming increasingly popular and better at mimicking human language. In trustsensitive decisions, such as plagiarism and fraud detection, identifying AI-generated texts poses larger difficulties":" decisions need to be made explainable to ensure trust and accountability. To support users in identifying AI-generated texts, we propose the tool UNCOVER. The tool analyses texts through three explainable linguistic approaches":" Stylometric writing style analysis, topic modeling, and entity recognition. The result of the tool is a decision and visualizations on the analysis results. We evaluate the tool on news articles by means of accuracy of the decision and an expert study with 13 participants. The final prediction is based on classification of stylometric and evolving topic analysis. It achieved an accuracy of 70.4 % and a weighted F1-score of 85.6 %. The participants preferred to base their assessment on the prediction and the topic graph. However, they found the entity recognition to be an ineffective indicator. Moreover, five participants highlighted the explainable aspects of UNCOVER and overall the participants achieved 69 % true classifications. Eight participants expressed interest to continue using unCover for identifying AI-generated texts. In press</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2023-kdir-unblock"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="2023-kdir-unblock.bib" href="/bibliography/2023-kdir-unblock.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2023-kdir-unblock" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2023-kdir-unblock">@InProceedings{lbscsd2023-uncover,
  author       = {Liebe, Lucas and Baum, Jannis and Sch{\&quot;u}tze, Tilman and Cech, Tim and Scheibel, Willy and D{\&quot;o}llner, J{\&quot;u}rgen},
  title        = {\textsc{unCover}: Identifying AI Generated News Articles by Linguistic Analysis and Visualization},
  booktitle    = {Proceedings of the 15th International Conference on Knowledge Discovery and Information Retrieval},
  series       = {KDIR '23},
  publisher    = {SciTePress},
  organization = {INSTICC},
  year         = {2023},
  note         = {in press},
}

</pre></div></div></div></div><div class="row" id="2023-kdir-counterfactuals"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2023-kdir-counterfactuals.webp" alt="Thumbnail of Visual Counterfactual Explanations Using Semantic Part Locations"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Visual Counterfactual Explanations Using Semantic Part Locations</h3><p></p>15th International Conference on Knowledge Discovery and Information Retrieval (KDIR 2023),<p><small>Florence Böttger, Tim Cech, Willy Scheibel, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2023-kdir-counterfactuals">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2023-kdir-counterfactuals">BibTeX</a></p><div class="collapse abstract" data-bs-target id="abstract-2023-kdir-counterfactuals"><p>As machine learning models are becoming more widespread and see use in high-stake decisions, the explainability of these decisions is getting more relevant. One approach for explainability are counterfactual explanations. They are defined as changes to a data point such that it appears as a different class. Their close connection to the original dataset aids their explainability. However, existing methods of creating counterfacual explanations often rely on other machine learning models, which adds an additional layer of opacity to the explanations. We propose additions to an established pipeline for creating visual counterfacual explanations by using an inherently explainable algorithm that does not rely on external models. Using annotated semantic part locations, we replace parts of the counterfactual creation process. We evaluate the approach on the CUB-200-2011 dataset. Our approach outperforms the previous results":" we improve (1) the average number of edits by 0.1 edits, (2) the key point accuracy of editing within any semantic parts of the image by an average of at least 7 percentage points, and (3) the key point accuracy of editing the same semantic parts by at least 17 percentage points. In press</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2023-kdir-counterfactuals"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="2023-kdir-counterfactuals.bib" href="/bibliography/2023-kdir-counterfactuals.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2023-kdir-counterfactuals" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2023-kdir-counterfactuals">@InProceedings{btwd2023-counterfactuals,
  author       = {B{&quot;\o}ttger, Florence and Cech, Tim and Scheibel, Willy and D{\&quot;o}llner, J{\&quot;u}rgen},
  title        = {Visual Counterfactual Explanations Using Semantic Part Locations},
  booktitle    = {Proceedings of the 15th International Conference on Knowledge Discovery and Information Retrieval},
  series       = {KDIR '23},
  publisher    = {SciTePress},
  organization = {INSTICC},
  year         = {2023},
  note         = {in press},
}

</pre></div></div></div></div><div class="row" id="2023-ieeevis-drs"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2023-vis-evaluation-tm-dr.webp" alt="Thumbnail of Large-Scale Evaluation of Topic Models and Dimensionality Reduction Methods for 2D Text Spatialization"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Large-Scale Evaluation of Topic Models and Dimensionality Reduction Methods for 2D Text Spatialization</h3><p></p>34th IEEE Visualization Conference (IEEE Vis 2023),<p><small>Daniel Atzberger *, Tim Cech * (* Both authors contributed equally to this work), Willy Scheibel, Matthias Trapp, Rico Richter, Jürgen Döllner, and Tobias Schreck</small></p><p><a data-bs-toggle="collapse" href="#abstract-2023-ieeevis-drs">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2023-ieeevis-drs">BibTeX</a>&ensp;|&ensp;<a href="https://arxiv.org/abs/2307.11770">Paper (Pre-Print)</a></p><div class="collapse abstract" data-bs-target id="abstract-2023-ieeevis-drs"><p>Topic models are a class of unsupervised learning algorithms for detecting the semantic structure within a text corpus. Together with a subsequent dimensionality reduction algorithm, topic models can be used for deriving spatializations for text corpora as two-dimensional scatter plots, reflecting semantic similarity between the documents and supporting corpus analysis. Although the choice of the topic model, the dimensionality reduction, and their underlying hyperparameters significantly impact the resulting layout, it is unknown which particular combinations result in high-quality layouts with respect to accuracy and perception metrics. To investigate the effectiveness of topic models and dimensionality reduction methods for the spatialization of corpora as two-dimensional scatter plots (or basis for landscape-type visualizations), we present a large-scale, benchmark-based computational evaluation. Our evaluation consists of (1) a set of corpora, (2) a set of layout algorithms that are combinations of topic models and dimensionality reductions, and (3) quality metrics for quantifying the resulting layout. The corpora are given as document-term matrices, and each document is assigned to a thematic class. The chosen metrics quantify the preservation of local and global properties and the perceptual effectiveness of the two-dimensional scatter plots. By evaluating the benchmark on a computing cluster, we derived a multivariate dataset with over 45 000 individual layouts and corresponding quality metrics. Based on the results, we propose guidelines for the effective design of text spatializations that are based on topic models and dimensionality reductions. As a main result, we show that interpretable topic models are beneficial for capturing the structure of text corpora. We furthermore recommend the use of t-SNE as a subsequent dimensionality reduction.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2023-ieeevis-drs"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="2023-ieeevis.bib" href="/bibliography/2023-ieeevis.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2023-ieeevis-drs" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2023-ieeevis-drs">@Article{acstrds2023-evaluation-tm-dr,
  author       = {Atzberger, Daniel and Cech, Tim and Scheibel, Willy and Trapp, Matthias and Richter, Rico and D{\&quot;o}llner, J{\&quot;u}rgen and Schreck, Tobias},
  title        = {Large-Scale Evaluation of Topic Models and Dimensionality Reduction Methods for 2D Text Spatialization},
  journal      = {IEEE Transactions on Visualization and Computer Graphics},
  year         = {2023},
  publisher    = {IEEE},
  note         = {in press}
}
</pre></div></div></div></div><div class="row" id="2023-eurovis-saliency-maps"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2023-eurovis-saliencnn.webp" alt="Thumbnail of A Dashboard for Interactive Convolutional Neural Network Training And Validation Through Saliency Maps"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>A Dashboard for Interactive Convolutional Neural Network Training And Validation Through Saliency Maps</h3><p></p>25th EG Conference on Visualization (EuroVis 2023),<p><small>Tim Cech, Furkan Simsek, Willy Scheibel, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2023-eurovis-saliency-maps">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2023-eurovis-saliency-maps">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.2312/evp.20231054">DOI</a>&ensp;|&ensp;<a href="https://diglib.eg.org/handle/10.2312/evp20231054">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2023-eurovis-saliency-maps"><p>Quali-quantitative methods provide ways for interrogating Convolutional Neural Networks (CNN). For it, we propose a dashboard using a quali-quantitative method based on quantitative metrics and saliency maps. By those means, a user can discover patterns during the training of a CNN. With this, they can adapt the training hyperparameters of the model, obtaining a CNN that learned patterns desired by the user. Furthermore, they neglect CNNs which learned undesirable patterns. This improves users' agency over the model training process.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2023-eurovis-saliency-maps"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="2023-eurovis.bib" href="/bibliography/2023-eurovis.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2023-eurovis-saliency-maps" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2023-eurovis-saliency-maps">@inproceedings {10.2312:evp.20231054,
booktitle = {EuroVis 2023 - Posters},
editor = {Gillmann, Christina and Krone, Michael and Lenti, Simone},
title = {{A Dashboard for Interactive Convolutional Neural Network Training And Validation Through Saliency Maps}},
author = {Cech, Tim and Simsek, Furkan and Scheibel, Willy and Döllner, Jürgen},
year = {2023},
publisher = {The Eurographics Association},
ISBN = {978-3-03868-220-2},
DOI = {10.2312/evp.20231054}
}
</pre></div></div></div></div><div class="row" id="2023-swqd-defect-prediction"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2023-swqd-defect-prediction.webp" alt="Thumbnail of Outlier Mining Techniques for Software Defect Prediction"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Outlier Mining Techniques for Software Defect Prediction</h3><p></p>Software Quality Days (SWQD) 2023,<p><small>Tim Cech, Daniel Atzberger, Willy Scheibel, Sanjay Misra, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2023-swqd-defect-prediction">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2023-swqd-defect-prediction">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1007/978-3-031-31488-9_3">DOI</a>&ensp;|&ensp;<a href="https://link.springer.com/chapter/10.1007/978-3-031-31488-9_3">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2023-swqd-defect-prediction"><p>Software metrics measure aspects related to the quality of software. Using software metrics as a method of quantification of software, various approaches were proposed for locating defect-prone source code units within software projects. Most of these approaches rely on supervised learning algorithms, which require labeled data for adjusting their parameters during the learning phase. Usually, such labeled training data is not available. Unsupervised algorithms do not require training data and can therefore help to overcome this limitation. In this work, we evaluate the effect of unsupervised learning - especially outlier mining algorithms - for the task of defect prediction, i.e., locating defect-prone source code units. We investigate the effect of various class balancing and feature compressing techniques as preprocessing steps and show how sliding windows can be used to capture time series of source code metrics. We evaluate the Isolation Forest and Local Outlier Factor, as representants of outlier mining techniques. Our experiments on three publicly available datasets, containing a total of 11 software projects, indicate that the consideration of time series can improve static examinations by up to 3%. The results further show that supervised algorithms can outperform unsupervised approaches on all projects. Among all unsupervised approaches, the Isolation Forest achieves the best accuracy on 10 out of 11 projects.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2023-swqd-defect-prediction"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="2023-swqd.bib" href="/bibliography/2023-swqd.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2023-swqd-defect-prediction" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2023-swqd-defect-prediction">@InProceedings{10.1007/978-3-031-31488-9_3,
author=&quot;Cech, Tim
and Atzberger, Daniel
and Scheibel, Willy
and Misra, Sanjay
and D{\&quot;o}llner, J{\&quot;u}rgen&quot;,
editor=&quot;Mendez, Daniel
and Winkler, Dietmar
and Kross, Johannes
and Biffl, Stefan
and Bergsmann, Johannes&quot;,
title=&quot;Outlier Mining Techniques for Software Defect Prediction&quot;,
booktitle=&quot;Software Quality: Higher Software Quality through Zero Waste Development&quot;,
year=&quot;2023&quot;,
publisher=&quot;Springer Nature Switzerland&quot;,
pages=&quot;41--60&quot;,
isbn=&quot;978-3-031-31488-9&quot;
}

</pre></div></div></div></div><div class="row" id="2023-enase-outliers"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2023-enase-log-outlier.webp" alt="Thumbnail of Detecting Outliers in CI/CD Pipeline Logs using Latent Dirichlet Allocation"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Detecting Outliers in CI/CD Pipeline Logs using Latent Dirichlet Allocation</h3><p></p>18th International Conference on Evaluation of Novel Approaches to Software Engineering (ENASE 2023),<p><small>Daniel Atzberger, Tim Cech, Willy Scheibel, Rico Richter, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2023-enase-outliers">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2023-enase-outliers">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.5220/0011858500003464">DOI</a>&ensp;|&ensp;<a href="https://www.scitepress.org/Link.aspx?doi=10.5220/0011858500003464">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2023-enase-outliers"><p>Continuous Integration and Continuous Delivery are best practices used during the DevOps phase. By using automated pipelines for building and testing small software changes, possible risks are intended to be detected early. Those pipelines continuously generate log events that are collected in semi-structured log files. In an industry context, these log files can amass 100,000 events and more. However, the relevant sections in these log files must be manually tagged by the user. This paper presents an online-learning approach for detecting relevant log events using Latent Dirichlet Allocation. After grouping a fixed number of log events in a document, our approach prunes the vocabulary to eliminate words without semantic meaning. A sequence of documents is then described as a discrete sequence by applying Latent Dirichlet Allocation, which allows the detection of outliers within the sequence. Our approach provides an explanation of the results by integrating the latent variables of the model. The approach is tested on log files that originate from a CI/CD pipeline of a large German company. Our results indicate that whether or not a log event is marked as an outlier heavily depends on the chosen hyperparameters of our model.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2023-enase-outliers"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="2023-enase.bib" href="/bibliography/2023-enase.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2023-enase-outliers" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2023-enase-outliers">@InProceedings{acsd2023-log-outlier,
  author       = {Atzberger, Daniel and Cech, Tim and Scheibel, Willy and Richter, Rico and D{\&quot;o}llner, J{\&quot;u}rgen},
  title        = {Detecting Outliers in CI/CD Pipeline Logs using Latent Dirichlet Allocation},
  booktitle    = {Proceedings of the 18th International Conference Evaluation of Novel Approaches to Software Engineering},
  year         = {2023},
  series       = {ENASE '23},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0011858500003464},
  isbn         = {978-989-758-647-7},
  issn         = {2184-4895},
  pages        = {461--468},
}

</pre></div></div></div></div><div class="row" id="2023-ivapp-evaluating-ssnp"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2023-ivapp-evaluating-ssnp.webp" alt="Thumbnail of Evaluating Architectures and Hyperparameters of Self-supervised Network Projections"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Evaluating Architectures and Hyperparameters of Self-supervised Network Projections</h3><p></p>14th International Conference on Information Visualization Theory and Applications (IVAPP) 2023, 2023<p><small>Tim Cech, Daniel Atzberger, Willy Scheibel, Rico Richter, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2023-ivapp-evaluating-ssnp">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2023-ivapp-evaluating-ssnp">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.5220/0011699700003417">DOI</a>&ensp;|&ensp;<a href="https://www.scitepress.org/PublicationsDetail.aspx?ID=XGZYXVwPfcQ=&amp;t=1">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2023-ivapp-evaluating-ssnp"><p>Self-Supervised Network Projections (SSNP) are dimensionality reduction algorithms that produce low-dimensional layouts from high-dimensional data. By combining an autoencoder architecture with neighborhood information from a clustering algorithm, SSNP intend to learn an embedding that generates visually separated clusters. In this work, we extend an approach that uses cluster information as pseudo-labels for SSNP by taking outlier information into account. Furthermore, we investigate the influence of different autoencoders on the quality of the generated two-dimensional layouts. We report on two experiments on the autoencoder's architecture and hyperparameters, respectively, measuring nine metrics on eight labeled datasets from different domains, e.g., Natural Language Processing. The results indicate that the model's architecture and the choice of hyperparameter values can influence the layout with statistical significance, but none achieves the best result over all metrics. In addition, we found out that using outlier information for the pseudo-labeling approach can maintain global properties of the two-dimensional layout while trading-off local properties.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2023-ivapp-evaluating-ssnp"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="cech23-ssnp-architectures.bib" href="/bibliography/cech23-ssnp-architectures.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2023-ivapp-evaluating-ssnp" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2023-ivapp-evaluating-ssnp">@InProceedings{casrd2023-evaluating-ssnp,
  author       = {Cech, Tim and Atzberger, Daniel and Scheibel, Willy and Richter, Rico and D{\&quot;o}llner, J{\&quot;u}rgen},
  title        = {Evaluating Architectures and Hyperparameters of Self-supervised Network Projections},
  booktitle    = {Proceedings of the 18th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications -- Volume 3 IVAPP},
  year         = {2023},
  series       = {IVAPP '23},
  publisher    = {SciTePress},
  organization = {INSTICC}
}
</pre></div></div></div></div><div class="row" id="2023-ivapp-software-forest-extended"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2023-ivapp-software-forest-extended.webp" alt="Thumbnail of Visualization of Source Code Similarity using 2.5D Semantic Software Maps"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Visualization of Source Code Similarity using 2.5D Semantic Software Maps</h3><p></p>VISIGRAPP 2021: Computer Vision, Imaging and Computer Graphics Theory and Applications, 2023<p><small>Daniel Atzberger, Tim Cech, Willy Scheibel, Daniel Limberger, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2023-ivapp-software-forest-extended">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2023-ivapp-software-forest-extended">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1007/978-3-031-25477-2_8">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/publication/363174745_CodeCV_Mining_Expertise_of_GitHub_Users_from_Coding_Activities#fullTextFileContent">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2023-ivapp-software-forest-extended"><p>For various program comprehension tasks, software visualization techniques can be beneficial by displaying aspects related to the behavior, structure, or evolution of software. In many cases, the question is related to the semantics of the source code files, e.g., the localization of files that implement specific features or the detection of files with similar semantics. This work presents a general software visualization technique for source code documents, which uses 3D glyphs placed on a two-dimensional reference plane. The relative positions of the glyphs captures their semantic relatedness. Our layout originates from applying Latent Dirichlet Allocation and Multidimensional Scaling on the comments and identifier names found in the source code files. Though different variants for 3D glyphs can be applied, we focus on cylinders, trees, and avatars. We discuss various mappings of data associated with source code documents to the visual variables of 3D glyphs for selected use cases and provide details on our visualization system.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2023-ivapp-software-forest-extended"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="atzberger2023-code-similarity.bib" href="/bibliography/atzberger2023-code-similarity.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2023-ivapp-software-forest-extended" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2023-ivapp-software-forest-extended">@inproceedings{atzberger2023-code-similarity,
  author = {Atzberger, Daniel and Cech, Tim and Scheibel, Willy and Limberger, Daniel and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Visualization of Source Code Similarity using 2.5D Semantic Software Maps},
  booktitle = {VISIGRAPP 2021: Computer Vision, Imaging and Computer Graphics Theory and Applications},
  year = {2023},
  publisher = {Springer},
}
</pre></div></div></div></div><div class="row" id="2022-vinci-topicmodel-benchmark"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2022-vinci-topicmodel-benchmark.webp" alt="Thumbnail of A Benchmark for the Use of Topic Models for Text Visualization Tasks"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>A Benchmark for the Use of Topic Models for Text Visualization Tasks</h3><p></p>Proc. ACM Int. Symp. on Visual Information Communication and Interaction (VINCI), 2022<p><small>Daniel Atzberger *, Tim Cech * (* Both authors contributed equally to this work), Willy Scheibel, Daniel Limberger, Matthias Trapp, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2022-vinci-topicmodel-benchmark">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2022-vinci-topicmodel-benchmark">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/3554944.3554961">DOI</a>&ensp;|&ensp;<a href="https://dl.acm.org/doi/pdf/10.1145/3554944.3554961">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2022-vinci-topicmodel-benchmark"><p>Based on the assumption that semantic relatedness between documents is reflected in the distribution of the vocabulary, topic models are a widely used technique for different analysis tasks. Their application results in concepts, the so-called topics, and a high-dimensional description of the documents. For visualization tasks, they can further be projected onto a lower-dimensional space using a dimension reduction technique. Though the quality of the resulting scatter plot mainly depends on the chosen layout technique and the choice of its hyperparameters, it is unclear which particular combinations of topic models and dimension reduction techniques are suitable for displaying the semantic relatedness between the documents. In this work, we propose a benchmark comprising various datasets, layout techniques, and quality metrics for conducting an empirical study on different such layout algorithms.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2022-vinci-topicmodel-benchmark"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="atzberger2022-topicmodel-benchmark.bib" href="/bibliography/atzberger2022-topicmodel-benchmark.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2022-vinci-topicmodel-benchmark" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2022-vinci-topicmodel-benchmark">@InProceedings{atzberger2022-topicmodel-benchmark,
  author    = {Atzberger, Daniel and Cech, Tim and Scheibel, Willy and Limberger, Daniel and D{\&quot;o}llner, J{\&quot;u}rgen and Trapp, Matthias},
  title     = {A Benchmark for the Use of Topic Models for Text Visualization Tasks},
  booktitle = {Proceedings of the 15th International Symposium on Visual Information Communication and Interaction},
  year      = {2022},
  series    = {VINCI~'22},
  publisher = {ACM},
}
</pre></div></div></div></div><div class="row" id="2022-scam-codecv"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2022-scam-codecv.webp" alt="Thumbnail of CodeCV: Mining Expertise of GitHub Users from Coding Activities"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>CodeCV: Mining Expertise of GitHub Users from Coding Activities</h3><p></p>22nd International Working Conference on Source Code Analysis and Manipulation (SCAM) 2022,<p><small>Daniel Atzberger, Nico Scordialo, Tim Cech, Willy Scheibel, Matthias Trapp, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2022-scam-codecv">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2022-scam-codecv">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1109/SCAM55253.2022.00021">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/publication/363175014_Visualization_of_Source_Code_Similarity_using_25D_Semantic_Software_Maps#fullTextFileContent">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2022-scam-codecv"><p>The number of software projects developed collaboratively on social coding platforms is steadily increasing. One of the motivations for developers to participate in open-source software development is to make their development activities easier accessible to potential employers, e.g., in the form of a resume for their interests and skills. However, manual review of source code activities is time-consuming and requires detailed knowledge of the technologies used. Existing approaches are limited to a small subset of actual source code activity and metadata and do not provide explanations for their results. In this work, we present CodeCV, an approach to analyzing the commit activities of a GitHub user concerning the use of programming languages, software libraries, and higher-level concepts, e.g., Machine Learning or Cryptocurrency. Skills in using software libraries and programming languages are analyzed based on syntactic structures in the source code. Based on Labeled Latent Dirichlet Allocation, an automatically generated corpus of GitHub projects is used to learn the concept-specific vocabulary in identifier names and comments. This enables the capture of expertise on abstract concepts from a user's commit history. CodeCV further explains the results through links to the relevant commits in an interactive web dashboard. We tested our system on selected GitHub users who mainly contribute to popular projects to demonstrate that our approach is able to capture developers' expertise effectively.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2022-scam-codecv"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="atzberger2022-mining-expertise.bib" href="/bibliography/atzberger2022-mining-expertise.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2022-scam-codecv" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2022-scam-codecv">@InProceedings{ascstd2022-codecv,
  author       = {Atzberger, Daniel and Scordialo, Nico and Cech, Tim and Scheibel, Willy and Trapp, Matthias and D{\&quot;o}llner, J{\&quot;u}rgen},
  title        = {CodeCV: Mining Expertise of GitHub Users from Coding Activities},
  booktitle    = {Proceedings of the 22nd International Working Conference on Source Code Analysis and Manipulation},
  year         = {2022},
  series       = {SCAM '22},
  publisher    = {IEEE},
  doi          = {10.1109/SCAM55253.2022.00021},
}

</pre></div></div></div></div><div class="row" id="2022-iccsa-prometheus"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2022-iccsa-prometheus.webp" alt="Thumbnail of Efficient GitHub Crawling using the GraphQL API"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Efficient GitHub Crawling using the GraphQL API</h3><p></p>22th International Conference on Computational Science and Its Applications (ICCSA) 2022, 2022<p><small>Adrian Jobst, Daniel Atzberger, Tim Cech, Willy Scheibel, Matthias Trapp, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2022-iccsa-prometheus">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2022-iccsa-prometheus">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1007/978-3-031-10548-7_48">DOI</a></p><div class="collapse abstract" data-bs-target id="abstract-2022-iccsa-prometheus"><p>The number of publicly accessible software repositories on online platforms is growing rapidly. With more than 128 million public repositories (as of March 2020), GitHub is the world’s largest platform for hosting and managing software projects. Where it used to be necessary to merge various data sources, it is now possible to access a wealth of data using the GitHub API alone. However, collecting and analyzing this data is not an easy endeavor. In this paper, we present Prometheus, a system for crawling and storing software repositories from GitHub. Compared to existing frameworks, Prometheus follows an event-driven microservice architecture. By separating functionality on the service level, there is no need to understand implementation details or use existing frameworks to extend or customize the system, only data. Prometheus consists of two components, one for fetching GitHub data and one for data storage which serves as a basis for future functionality. Unlike most existing crawling approaches, the Prometheus fetching service uses the GitHub GraphQL API. As a result, Prometheus can significantly outperform alternatives in terms of throughput in some scenarios.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2022-iccsa-prometheus"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="jobst2022-github-crawling.bib" href="/bibliography/jobst2022-github-crawling.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2022-iccsa-prometheus" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2022-iccsa-prometheus">@InProceedings{jacstd2022-prometheus,
  author       = {Jobst, Adrian and Atzberger, Daniel and Cech, Tim and Scheibel, Willy and Trapp, Matthias and D{\&quot;o}llner, J{\&quot;u}rgen},
  title        = {Efficient GitHub Crawling using the GraphQL API},
  booktitle    = {Proceedings of the 22th International Conference on Computational Science and Its Applications},
  year         = {2022},
  series       = {ICCSA '22},
  publisher    = {Springer},
  pages        = {662--677},
  doi          = {10.1007/978-3-031-10548-7_48}
}

</pre></div></div></div></div><div class="row" id="2022-ivapp-knowhow-map"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2022-ivapp-knowhow-map.webp" alt="Thumbnail of Visualization of Knowledge Distribution across Development Teams using 2.5D Semantic Software Maps"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Visualization of Knowledge Distribution across Development Teams using 2.5D Semantic Software Maps</h3><p></p>Proc. Int. Conf. on Information Visualization Theory and Applications (IVAPP), 2022<p><small>Daniel Atzberger, Tim Cech, Adrian Jobst, Willy Scheibel, Daniel Limberger, Matthias Trapp, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2022-ivapp-knowhow-map">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2022-ivapp-knowhow-map">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.5220/0010991100003124">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Matthias-Trapp-2/publication/358523984/inline/jsViewer/62061c62afa8884cabd8675c">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2022-ivapp-knowhow-map"><p>In order to detect software risks at an early stage, various software visualization techniques have been developed for monitoring the structure, behaviour, or the underlying development process of software. One of greatest risks for any IT organization consists in an inappropriate distribution of knowledge among its developers, as a projects' success mainly depends on assigning tasks to developers with the required skills and expertise. In this work, we address this problem by proposing a novel Visual Analytics framework for mining and visualizing the expertise of developers based on their source code activities. Under the assumption that a developer's knowledge about code is represented directly through comments and the choice of identifier names, we generate a 2D layout using Latent Dirichlet Allocation together with Multidimensional Scaling on the commit history, thus displaying the semantic relatedness between developers. In order to capture a developer's expertise in a concept, we utilize Labeled LDA trained on a corpus of Open Source projects. By mapping aspects related to skills onto the visual variables of 3D glyphs, we generate a 2.5D Visualization, we call KnowhowMap. We exemplify this approach with an interactive prototype that enables users to analyze the distribution of skills and expertise in an explorative way.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2022-ivapp-knowhow-map"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="atzberger2022-knowhow-map.bib" href="/bibliography/atzberger2022-knowhow-map.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2022-ivapp-knowhow-map" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2022-ivapp-knowhow-map">@inproceedings{atzberger2022-knowhow-map,
  author = {Atzberger, Daniel and Cech, Tim and Jobst, Adrian and Scheibel, Willy and Limberger, Daniel and Trapp, Matthias and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Visualization of Knowledge Distribution across Development Teams using 2.5D Semantic Software Maps},
  booktitle = {Proceedings of the 17th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - IVAPP},
  year = {2022},
  series = {IVAPP~'22},
  publisher = {SciTePress},
  pages = {210--217},
  doi = {10.5220/0010991100003124},
  isbn = {978-9-897585-55-5},
}
</pre></div></div></div></div><div class="row" id="2021-ivapp-software-forest"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2021-ivapp-software-forest.webp" alt="Thumbnail of Software Forest: A Visualization of Semantic Similarities in Source Code using a Tree Metaphor (in context of the Master`s Project)"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Software Forest: A Visualization of Semantic Similarities in Source Code using a Tree Metaphor (in context of the Master`s Project)</h3><p></p>12th International Conference on Information Visualization Theory and Applications (IVAPP) 2021, 2021<p><small>Daniel Atzberger, Tim Cech, Merlin de la Haye, Maximilian Söchting, Willy Scheibel, Daniel Limberger, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2021-ivapp-software-forest">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2021-ivapp-software-forest">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.5220/0010267601120122">DOI</a></p><div class="collapse abstract" data-bs-target id="abstract-2021-ivapp-software-forest"><p>Software visualization techniques provide effective means for program comprehension tasks as they allow developers to interactively explore large code bases. A frequently encountered task during software development is the detection of source code files of similar semantic. To assist this task we present Software Forest, a novel 2.5D software visualization that enables interactive exploration of semantic similarities within a software system, illustrated as a forest. The underlying layout results from the analysis of the vocabulary of the software documents using Latent Dirichlet Allocation and Multidimensional Scaling and therefore reflects the semantic similarity between source code files. By mapping properties of a software entity, e.g., size metrics or trend data, to visual variables encoded by various, figurative tree meshes, aspects of a software system can be displayed. This concept is complemented with implementation details as well as a discussion on applications.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2021-ivapp-software-forest"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="atzberger2021-software-forest.bib" href="/bibliography/atzberger2021-software-forest.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2021-ivapp-software-forest" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2021-ivapp-software-forest">@inproceedings{atzberger2021-software-forest,
  author = {Atzberger, Daniel and Cech, Tim and de la Haye, Merlin and S{\&quot;o}chting, Maximilian and Scheibel, Willy and Limberger, Daniel and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Software Forest: A Visualization of Semantic Similarities in Source Code using a Tree Metaphor},
  booktitle = {Proceedings of the 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
  year = {2021},
  series = {IVAPP~'21},
  publisher = {SciTePress},
  pages = {112--122},
  doi = {10.5220/0010267601120122},
  isbn = {978-9-897584-88-6},
}
</pre></div></div></div></div></section><section class="container" id="footer"><footer><div class="row text-center"><div class="col-12"><p class="mt-5 mb-1">&copy; 2023&thinsp;&ndash;&thinsp;2023 Cech Tim</p><small class="mt-0 mb-5"><span class="text-muted">This website was last updated on 08/01/2023</span>&ensp;|&ensp;<a class="text-muted" href="privacy-policy.html">Privacy Policy</a>&ensp;|&ensp;<a class="text-muted" href="https://github.com/Oluwoye/">Source Code (GitHub)</a></small></div></div><data hidden value="b52d6fc">revision</data></footer></section></body><script src="/bootstrap.js"></script><script src="/scripts.js"></script></html>