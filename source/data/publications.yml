
heading: Publications
orcid: 0000-0001-8688-2419
researchgate: Tim_Cech
scholar: phn3_p8AAAAJ

publications:


- key: 2023-eurovis-saliency-maps
  bibtex: 2023-eurovis
  title: 'A Dashboard for Interactive Convolutional Neural Network Training And Validation Through Saliency Maps'
  date: ''
  authors:
  - Tim Cech
  - Furkan Simsek
  - Willy Scheibel
  - Jürgen Döllner
  published: '25th EG Conference on Visualization (EuroVis 2023)'
  abstract:
    Quali-quantitative methods provide ways for interrogating Convolutional Neural Networks (CNN). For it, we propose a dashboard using a quali-quantitative method based on quantitative metrics and saliency maps. By those means, a user can discover patterns during the training of a CNN. With this, they can adapt the training hyperparameters of the model, obtaining a CNN that learned patterns desired by the user. Furthermore, they neglect CNNs which learned undesirable patterns. This improves users' agency over the model training process.
  thumbnail: 2023-eurovis-saliencnn.webp
  downloads:
    - href: https://diglib.eg.org/handle/10.2312/evp20231054
      desc: Paper

- key: 2023-swqd-defect-prediction
  bibtex: 2023-swqd
  title: 'Outlier Mining Techniques for Software Defect Prediction'
  date: ''
  authors:
  - Tim Cech
  - Daniel Atzberger
  - Willy Scheibel
  - Sanjay Misra
  - Jürgen Döllner
  published: 'Software Quality Days (SWQD) 2023'
  abstract:
    Software metrics measure aspects related to the quality of software. Using software metrics as a method of quantification of software, various approaches were proposed for locating defect-prone source code units within software projects.
     Most of these approaches rely on supervised learning algorithms, which require labeled data for adjusting their parameters during the learning phase. Usually, such labeled training data is not available.
     Unsupervised algorithms do not require training data and can therefore help to overcome this limitation. In this work, we evaluate the effect of unsupervised learning - especially outlier mining algorithms - for the task of defect prediction,
      i.e., locating defect-prone source code units. We investigate the effect of various class balancing and feature compressing techniques as preprocessing steps and show how sliding windows can be used to capture time series of source code metrics.
       We evaluate the Isolation Forest and Local Outlier Factor, as representants of outlier mining techniques.
        Our experiments on three publicly available datasets, containing a total of 11 software projects, indicate that the consideration of time series can improve static examinations by up to 3%.
         The results further show that supervised algorithms can outperform unsupervised approaches on all projects. Among all unsupervised approaches, the Isolation Forest achieves the best accuracy on 10 out of 11 projects.  
  thumbnail: 2023-swqd-defect-prediction.webp
  downloads:
    - href: https://doi.org/10.1007/978-3-031-31488-9_3
      desc: DOI
    - href: https://link.springer.com/chapter/10.1007/978-3-031-31488-9_3
      desc: Paper
      
- key: 2023-enase-outliers
  bibtex: 2023-enase
  title: 'Detecting Outliers in CI/CD Pipeline Logs using Latent Dirichlet Allocation'
  date: ''
  authors:
  - Daniel Atzberger
  - Tim Cech
  - Willy Scheibel
  - Rico Richter
  - Jürgen Döllner
  published: '18th International Conference on Evaluation of Novel Approaches to Software Engineering (ENASE 2023)'
  abstract:
    Continuous Integration and Continuous Delivery are best practices used during the DevOps phase. By using automated pipelines for building and testing small software changes, possible risks are intended to be detected early. Those pipelines continuously generate log events that are collected in semi-structured log files. In an industry context, these log files can amass 100,000 events and more. However, the relevant sections in these log files must be manually tagged by the user. This paper presents an online-learning approach for detecting relevant log events using Latent Dirichlet Allocation. After grouping a fixed number of log events in a document, our approach prunes the vocabulary to eliminate words without semantic meaning. A sequence of documents is then described as a discrete sequence by applying Latent Dirichlet Allocation, which allows the detection of outliers within the sequence. Our approach provides an explanation of the results by integrating the latent variables of the model. The approach is tested on log files that originate from a CI/CD pipeline of a large German company. Our results indicate that whether or not a log event is marked as an outlier heavily depends on the chosen hyperparameters of our model. 
  thumbnail: 2023-enase-log-outlier.webp
  downloads:
    - href: https://doi.org/10.5220/0011858500003464
      desc: DOI
    - href: https://www.scitepress.org/Link.aspx?doi=10.5220/0011858500003464
      desc: Paper

- key: 2023-ivapp-evaluating-ssnp
  bibtex: cech23-ssnp-architectures
  title: 'Evaluating Architectures and Hyperparameters of Self-supervised Network Projections'
  date: '2023-03-06'
  authors:
  - Tim Cech
  - Daniel Atzberger
  - Willy Scheibel
  - Rico Richter
  - Jürgen Döllner
  published: '14th International Conference on Information Visualization Theory and Applications (IVAPP) 2023'
  abstract:
    Self-Supervised Network Projections (SSNP) are dimensionality reduction algorithms that produce low-dimensional layouts from high-dimensional data. By combining an autoencoder architecture with neighborhood information from a clustering algorithm, SSNP intend to learn an 
    embedding that generates visually separated clusters. In this work, we extend an approach that uses cluster information as pseudo-labels for SSNP by taking outlier information into account. Furthermore, we investigate the influence of different autoencoders on the quality of 
    the generated two-dimensional layouts. We report on two experiments on the autoencoder's architecture and hyperparameters, respectively, measuring nine metrics on eight labeled datasets from different domains, e.g., Natural Language Processing. The results indicate that the 
    model's architecture and the choice of hyperparameter values can influence the layout with statistical significance, but none achieves the best result over all metrics. In addition, we found out that using outlier information for the pseudo-labeling approach can maintain 
    global properties of the two-dimensional layout while trading-off local properties.
  thumbnail: 2023-ivapp-evaluating-ssnp.webp
  downloads:
    - href: https://doi.org/10.5220/0011699700003417
      desc: DOI
    - href: https://www.scitepress.org/PublicationsDetail.aspx?ID=XGZYXVwPfcQ=&t=1
      desc: Paper

- key: 2022-vinci-topicmodel-benchmark
  bibtex: atzberger2022-topicmodel-benchmark
  title: 'A Benchmark for the Use of Topic Models for Text Visualization Tasks'
  date: '2022-08-16'
  authors:
  - Daniel Atzberger *
  - Tim Cech * (* Both authors contributed equally to this work)
  - Willy Scheibel
  - Daniel Limberger
  - Matthias Trapp
  - Jürgen Döllner
  published: Proc. ACM Int. Symp. on Visual Information Communication and Interaction (VINCI)
  abstract:
    Based on the assumption that semantic relatedness between documents is reflected in the distribution of the vocabulary, topic models are a widely used technique for different analysis tasks.
    Their application results in concepts, the so-called topics, and a high-dimensional description of the documents.
    For visualization tasks, they can further be projected onto a lower-dimensional space using a dimension reduction technique.
    Though the quality of the resulting scatter plot mainly depends on the chosen layout technique and the choice of its hyperparameters, it is unclear which particular combinations of topic models and dimension reduction techniques are suitable for displaying the semantic 
    relatedness between the documents.
    In this work, we propose a benchmark comprising various datasets, layout techniques, and quality metrics for conducting an empirical study on different such layout algorithms.
  thumbnail: 2022-vinci-topicmodel-benchmark.webp
  downloads:
    - href: https://doi.org/10.1145/3554944.3554961
      desc: DOI
    - href: https://dl.acm.org/doi/pdf/10.1145/3554944.3554961
      desc: Paper
  
- key: 2023-ivapp-software-forest-extended
  bibtex: atzberger2023-code-similarity
  title: 'Visualization of Source Code Similarity using 2.5D Semantic Software Maps'
  date: '2023-02-01'
  authors:
  - Daniel Atzberger
  - Tim Cech
  - Willy Scheibel
  - Daniel Limberger
  - Jürgen Döllner
  published: 'VISIGRAPP 2021: Computer Vision, Imaging and Computer Graphics Theory and Applications'
  abstract:
    For various program comprehension tasks, software visualization techniques can be beneficial by displaying aspects related to the behavior, structure, or evolution of software. 
    In many cases, the question is related to the semantics of the source code files, e.g., the localization of files that implement specific features or the detection of files with similar semantics. 
    This work presents a general software visualization technique for source code documents, which uses 3D glyphs placed on a two-dimensional reference plane. 
    The relative positions of the glyphs captures their semantic relatedness. 
    Our layout originates from applying Latent Dirichlet Allocation and Multidimensional Scaling on the comments and identifier names found in the source code files. 
    Though different variants for 3D glyphs can be applied, we focus on cylinders, trees, and avatars. 
    We discuss various mappings of data associated with source code documents to the visual variables of 3D glyphs for selected use cases and provide details on our visualization system. 
  thumbnail: 2023-ivapp-software-forest-extended.webp

- key: 2022-scam-codecv
  bibtex: atzberger2022-mining-expertise
  title: 'CodeCV: Mining Expertise of GitHub Users from Coding Activities'
  date: ''
  authors:
  - Daniel Atzberger
  - Nico Scordialo
  - Tim Cech
  - Willy Scheibel
  - Matthias Trapp
  - Jürgen Döllner
  published: '22nd International Working Conference on Source Code Analysis and Manipulation (SCAM) 2022'
  abstract:
    The number of software projects developed collaboratively on social coding platforms is steadily increasing. One of the motivations for developers to participate in open-source software development is to make their development activities easier accessible to potential 
    employers, e.g., in the form of a resume for their interests and skills. However, manual review of source code activities is time-consuming and requires detailed knowledge of the technologies used. Existing approaches are limited to a small subset of actual source code 
    activity and metadata and do not provide explanations for their results. In this work, we present CodeCV, an approach to analyzing the commit activities of a GitHub user concerning the use of programming languages, software libraries, and higher-level concepts, e.g., Machine 
    Learning or Cryptocurrency. Skills in using software libraries and programming languages are analyzed based on syntactic structures in the source code. Based on Labeled Latent Dirichlet Allocation, an automatically generated corpus of GitHub projects is used to learn the 
    concept-specific vocabulary in identifier names and comments. This enables the capture of expertise on abstract concepts from a user's commit history. CodeCV further explains the results through links to the relevant commits in an interactive web dashboard. We tested our 
    system on selected GitHub users who mainly contribute to popular projects to demonstrate that our approach is able to capture developers' expertise effectively.
    
    In press 
  thumbnail: 2022-scam-codecv.webp
  
- key: 2022-ivapp-knowhow-map
  bibtex: atzberger2022-knowhow-map
  title: 'Visualization of Knowledge Distribution across Development Teams using 2.5D Semantic Software Maps'
  date: '2022-02-08'
  authors:
  - Daniel Atzberger
  - Tim Cech
  - Adrian Jobst
  - Willy Scheibel
  - Daniel Limberger
  - Matthias Trapp
  - Jürgen Döllner
  published: Proc. Int. Conf. on Information Visualization Theory and Applications (IVAPP)
  abstract:
    In order to detect software risks at an early stage, various software visualization techniques have been developed for monitoring the structure, behaviour, or the underlying development process of software.
    One of greatest risks for any IT organization consists in an inappropriate distribution of knowledge among its developers, as a projects' success mainly depends on assigning tasks to developers with the required skills and expertise.
    In this work, we address this problem by proposing a novel Visual Analytics framework for mining and visualizing the expertise of developers based on their source code activities.
    Under the assumption that a developer's knowledge about code is represented directly through comments and the choice of identifier names, we generate a 2D layout using Latent Dirichlet Allocation together with Multidimensional Scaling on the commit history, thus displaying 
    the semantic relatedness between developers.
    In order to capture a developer's expertise in a concept, we utilize Labeled LDA trained on a corpus of Open Source projects.
    By mapping aspects related to skills onto the visual variables of 3D glyphs, we generate a 2.5D Visualization, we call KnowhowMap.
    We exemplify this approach with an interactive prototype that enables users to analyze the distribution of skills and expertise in an explorative way.
  thumbnail: 2022-ivapp-knowhow-map.webp
  downloads:
    - href: https://doi.org/10.5220/0010991100003124
      desc: DOI
    - href: https://www.researchgate.net/profile/Matthias-Trapp-2/publication/358523984/inline/jsViewer/62061c62afa8884cabd8675c
      desc: Paper

- key: 2022-iccsa-prometheus
  bibtex: jobst2022-github-crawling
  title: 'Efficient GitHub Crawling using the GraphQL API'
  date: '2022-07-26'
  authors:
  - Adrian Jobst
  - Daniel Atzberger
  - Tim Cech
  - Willy Scheibel
  - Matthias Trapp
  - Jürgen Döllner
  published: '22th International Conference on Computational Science and Its Applications (ICCSA) 2022'
  abstract:
    The number of publicly accessible software repositories on online platforms is growing rapidly. With more than 128 million public repositories (as of March 2020), GitHub is the world’s largest platform for hosting and managing software projects. Where it used to be necessary 
    to merge various data sources, it is now possible to access a wealth of data using the GitHub API alone. However, collecting and analyzing this data is not an easy endeavor. In this paper, we present Prometheus, a system for crawling and storing software repositories from 
    GitHub. Compared to existing frameworks, Prometheus follows an event-driven microservice architecture. By separating functionality on the service level, there is no need to understand implementation details or use existing frameworks to extend or customize the system, only 
    data. Prometheus consists of two components, one for fetching GitHub data and one for data storage which serves as a basis for future functionality. Unlike most existing crawling approaches, the Prometheus fetching service uses the GitHub GraphQL API. As a result, Prometheus 
    can significantly outperform alternatives in terms of throughput in some scenarios. 
  thumbnail: 2022-iccsa-prometheus.webp
  downloads:
    - href: https://doi.org/10.1007/978-3-031-10548-7_48
      desc: DOI
  
- key: 2021-ivapp-software-forest
  bibtex: atzberger2021-software-forest
  title: 'Software Forest: A Visualization of Semantic Similarities in Source Code using a Tree Metaphor (in context of the Master`s Project)'
  date: '2021-01-01'
  authors:
  - Daniel Atzberger
  - Tim Cech
  - Merlin de la Haye
  - Maximilian Söchting
  - Willy Scheibel
  - Daniel Limberger
  - Jürgen Döllner
  published: '12th International Conference on Information Visualization Theory and Applications (IVAPP) 2021'
  abstract:
    Software visualization techniques provide effective means for program comprehension tasks as they allow developers to interactively explore large code bases. A frequently encountered task during software development is the detection of source code files of similar semantic. 			
    To assist this task we present Software Forest, a novel 2.5D software visualization that enables interactive exploration of semantic similarities within a software system, illustrated as a forest. The underlying layout results from the analysis of the vocabulary of the 
    software documents using Latent Dirichlet Allocation and Multidimensional Scaling and therefore reflects the semantic similarity between source code files. By mapping properties of a software entity, e.g., size metrics or trend data, to visual variables encoded by various, 
    figurative tree meshes, aspects of a software system can be displayed. This concept is complemented with implementation details as well as a discussion on applications. 
  thumbnail: 2021-ivapp-software-forest.webp
  downloads:
    - href: https://doi.org/10.5220/0010267601120122
      desc: DOI

